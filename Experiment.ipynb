{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldm.data.nuscenes import NuScenesDataset\n",
    "from ldm.data.utils import draw_projected_bbox, visualize_lidar, focus_on_bbox\n",
    "from ldm.data.box_np_ops import points_in_bbox_corners\n",
    "from ldm.data.lidar_converter import LidarConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything\n",
    "seed = 3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "dataset = NuScenesDataset(\n",
    "    state=\"val\",\n",
    "    object_database_path=\"/mnt/data/mobi/mobi/data/nuscenes/nuscenes_dbinfos_pbe_val.csv\",\n",
    "    scene_database_path=\"/mnt/data/mobi/mobi/data/nuscenes/nuscenes_scene_infos_pbe_val.pkl\",\n",
    "    reference_image_min_h=300,\n",
    "    reference_image_min_w=300,\n",
    "    object_classes=[\"car\"],\n",
    "    use_lidar=True,\n",
    "    use_camera=True,\n",
    "    image_height=256,\n",
    "    image_width=256,\n",
    "    # rot_every_angle=30\n",
    "    # e0e3b665c44fa8d17d9f4770bdf9c',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "    # print(i)\n",
    "sample = dataset[1]\n",
    "bbox_3d = sample[\"bbox_3d\"]\n",
    "sample = sample[\"lidar\"]\n",
    "# image_tensor = sample[\"GT\"]\n",
    "image_tensor = sample[\"range_depth\"]\n",
    "\n",
    "def un_norm(x):\n",
    "    return (x+1.0)/2.0\n",
    "\n",
    "bbox_image_coords = sample['cond']['ref_bbox']\n",
    "\n",
    "GT_img = un_norm(image_tensor).cpu().numpy().transpose(1, 2, 0)\n",
    "GT_img = (GT_img * 255).astype(np.uint8)[..., ::-1]\n",
    "GT_img = draw_projected_bbox(GT_img, bbox_image_coords[..., :2], thickness=1)\n",
    "GT_img = GT_img[..., ::-1]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(GT_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_depth = np.array(sample['range_depth'])[0]\n",
    "range_depth_orig = sample['range_depth_orig']\n",
    "range_shift_left = sample[\"range_shift_left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_depth_unshift = np.roll(range_depth, range_shift_left, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(range_depth_orig[..., None], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(range_depth_unshift[..., None], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_converter = LidarConverter()\n",
    "range_depth_new, _ = lidar_converter.undo_default_transforms(\n",
    "    range_shift_left,\n",
    "    range_depth=range_depth_orig,\n",
    "    range_depth_crop=range_depth,\n",
    "    # mask=mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(range_depth_new, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_new, _ = lidar_converter.range2pcd(range_depth_new)\n",
    "points, _ = lidar_converter.range2pcd(range_depth_orig)\n",
    "bbox_3d_new = bbox_3d\n",
    "\n",
    "points, _ = focus_on_bbox(points, bbox_3d)\n",
    "points_new, bbox_3d_new = focus_on_bbox(points_new, bbox_3d)\n",
    "\n",
    "# mask = points_in_rbbox_corners(points, bbox_3d_new[None])\n",
    "# points = points[mask[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_vis_new = visualize_lidar(points_new, bboxes=bbox_3d_new)\n",
    "lidar_vis = visualize_lidar(points, bboxes=bbox_3d_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot them side by side\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Before inpainting\")\n",
    "plt.imshow(lidar_vis)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"After inpainting\")\n",
    "plt.imshow(lidar_vis_new)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find scene given picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"n015-2018-10-02-10-50-40+0800__CAM_FRONT__1538448761512460.jpg\"\n",
    "with open(\"data/nuscenes/nuscenes_scene_infos_pbe_val.pkl\", \"rb\") as f:\n",
    "    scenes_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_token, scene_info in scenes_info.items():\n",
    "    print(scene_info['image_paths'][0])\n",
    "    for image_path in scene_info['image_paths']:\n",
    "        if image in image_path:\n",
    "            print(scene_token)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "image_paths = os.listdir(\"/mnt/data/mobi/mobi/results_test_rotate/exp/results\")\n",
    "# sort\n",
    "image_paths = sorted(image_paths, key=lambda x: int(x.strip('.png').split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "images = []\n",
    "for image_path in image_paths:\n",
    "    img = cv2.imread(os.path.join(\"/mnt/data/mobi/mobi/results_test_rotate/exp/results\", image_path))\n",
    "    images.append(img)\n",
    "\n",
    "# create mp4 video\n",
    "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 1, (800, 450))\n",
    "for i in range(len(images)):\n",
    "    out.write(images[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from scripts.inference import load_model_from_config\n",
    "from ldm.util import instantiate_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_config(config, ckpt, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if len(m) > 0 and verbose:\n",
    "        print(\"missing keys:\")\n",
    "        print(m)\n",
    "    if len(u) > 0 and verbose:\n",
    "        print(\"unexpected keys:\")\n",
    "        print(u)\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"configs/nusc.yaml\")\n",
    "model = load_model_from_config(config, \"checkpoints/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"checkpoints/model.ckpt\", map_location=\"cpu\")['state_dict']\n",
    "model2 = torch.load(\"/mnt/data/transient/mobi/mobi/models/Paint-by-Example/2024-03-25T16-58-51_nusc/checkpoints/last.ckpt\", map_location=\"cpu\")['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in model2.keys():\n",
    "    if k not in model1.keys():\n",
    "        print(f\"{k} not in model1\")\n",
    "    elif not torch.equal(model1[k], model2[k]):\n",
    "        print(f\"{k} is not equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldm.lr_scheduler import LambdaLinearScheduler, LambdaWarmUpCosineScheduler2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LambdaLinearScheduler(\n",
    "    warm_up_steps=[0],\n",
    "    f_start=[1e-3],\n",
    "    cycle_lengths=[50000],\n",
    "    f_max=[1],\n",
    "    f_min=[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [scheduler.schedule(i) for i in range(50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(\"checkpoints/model.ckpt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['state_dict'] = {k: v for k, v in model['state_dict'].items() if \"first_stage_model\" not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"checkpoints/model_no-vae.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
